\documentclass[../../Thesis.tex]{subfiles}
\externaldocument{../Research_results/Research_results}
\externaldocument{../Data/Data}
\begin{document}
\section{Discussion}
\subsection{Results analysis}
\subsubsection{Best performers}
The data, as presented in Figures~\ref{figure:titleRanks} and~\ref{figure:abstractRanks} shows that the 10k/10k set performs better than all other TF-IDF sets, although the difference with the 5k/10k is low (1 median rank on abstract and 3 median ranks on the titles). For the embeddings, the TF-IDF weighted embedding works better than the others, although it is not a significant improvement (1 rank on a set of more than 3.000) compared to the default embeddings.
\subsubsection{TF-IDF}
The TF-IDF feature vectors outperform the embeddings on the abstracts, while the embeddings outperform the TF-IDF feature vectors on the titles. The main difference between the abstract and title is that the title contains fewer tokens compared to the abstract (see Table~\ref{table:corpusSize}). This means that the titles contain less information than the abstracts. Due to this, the TF-IDF method, which is purely based on word-occurrences \& counts has less information on the titles. The TF-IDF method works better on the abstract, containing more tokens than the tile, thus improving the differentiating the different abstract. The data furthermore shows that increasing the vocabulary size increases the performance of the TF-IDF, meaning that none of the created cut-off's resulted in cutting off noise.
\subsubsection{Limited TF-IDF embeddings}
The limited TF-IDF embeddings all underperform, compared to the TF-IDF embedding on median and average ranking. This result indicates that the noise reduction is too much, it removes meaningful words. If the noise reduction would be too low, we would only see a slight increase of performance compared to the TF-IDF embedding, or none at all. However, the rank increases, indicating the reduction in embedding quality due to missing words. This is in line with what we found with the TF-IDF results: higher vocabulary sizes give better performance. 
\begin{jumpin}
\textit{Rank distribution}.
However, Figures~\ref{figure:titleDistribution} and~\ref{figure:abstractDistribution} show that their rank distribution is different from the other embeddings. The rank distribution of the limited TF-IDF embeddings show the following pattern: a high/average performance on the top-rankings, an underperformance on the middle rankings and a resulting stack-up of articles with a high-ranking. This is further supported by the TF-IDF score on titles (Figure~\ref{figure:titleRanks}), on which the limited TF-IDF embeddings are the top performers, indicating a better performance on the top-1 articles compared to the other sets.
\end{jumpin}
The rank distribution seems to indicate that the cut-off was effective, but not for our purpose. The cut-off moved the "middle-ranked"  articles to either the higher end or the lower end of the rankings, resulting in high median and average ranks. The reduction in vocabulary size did not reduce the storage size for the embeddings, except for the 1K-6K embedding\footnote{This indicates that he 1K-6K embedding removed some articles entirely from the dataset.}.
\subsubsection{TF-IDF \& embeddings}
Our hypothesis on the difference between the TF-IDF and the standard embedding is as follows: The embeddings seem to outperform the TF-IDF feature vectors in situations where there is little information available (titles). This indicates that the embeddings store some word meaning that enables them to perform relatively well on the titles. The abstracts, on the other hand, contain much more information. Our data seems to indicate that the amount of information available in the abstracts enable the TF-IDF to cope with the lack of embedded information. \\
If this is the case, we could expect that there would little performance increase on the title when we compare the embeddings to the weighted TF-IDF embeddings, because the TF-IDF lacks the information to perform well, this can be seen in our data. We would also expect on the abstract an increase in performance since the TF-IDF has more information in this context. We would expect that the weighting applied by the TF-IDF improves the performance of the embedding by indicating word importance. Our data shows a minor improvement in performance of 1 median rank and 10 average ranks while these improvements cannot be seen as significant, our data at least indicates that weighting the embeddings with TF-IDF values has a positive effect on the embeddings.
\subsubsection{Memory usage}
Although the TF-IDF outperforms the embeddings on the abstracts, its memory usage is higher than the memory usage of the embeddings. The top-performing embedding, TF-IDF weighted embedding, uses 3.13 GB, the top performing TF-IDF, 10K/10K uses 11.61 GB, which is 270.93\% of the storage size needed for the embedding.
\end{document}